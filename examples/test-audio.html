<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Audio Opus Encode/Decode Test</title>
    <style>
      body {
        font-family: Arial, sans-serif;
        max-width: 900px;
        margin: 0 auto;
        padding: 20px;
        background: #f5f5f5;
      }
      h1 {
        text-align: center;
        color: #333;
      }
      .container {
        display: grid;
        grid-template-columns: 1fr 1fr;
        gap: 20px;
        margin-bottom: 20px;
      }
      .panel {
        background: white;
        padding: 20px;
        border-radius: 8px;
        box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
      }
      .panel-title {
        font-size: 14px;
        color: #666;
        margin: 0 0 10px 0;
        text-transform: uppercase;
        letter-spacing: 1px;
      }
      .controls {
        display: flex;
        gap: 10px;
        flex-wrap: wrap;
        margin-bottom: 15px;
      }
      button {
        padding: 10px 16px;
        background: #007bff;
        color: white;
        border: none;
        border-radius: 4px;
        cursor: pointer;
        font-size: 13px;
        font-weight: 500;
      }
      button:hover {
        background: #0056b3;
      }
      button:disabled {
        background: #ccc;
        cursor: not-allowed;
      }
      button.danger {
        background: #f44336;
      }
      button.danger:hover {
        background: #d32f2f;
      }
      .status {
        padding: 10px;
        border-radius: 4px;
        margin-bottom: 10px;
        font-size: 12px;
        background: #e7f3ff;
        border-left: 4px solid #007bff;
      }
      .status.error {
        background: #ffe7e7;
        border-left-color: #d32f2f;
      }
      .status.success {
        background: #e7ffe7;
        border-left-color: #4caf50;
      }
      .stats {
        background: #f9f9f9;
        padding: 10px;
        border-radius: 4px;
        font-size: 12px;
        font-family: monospace;
        max-height: 200px;
        overflow-y: auto;
      }
      .stat-line {
        padding: 4px 0;
        border-bottom: 1px solid #eee;
        display: flex;
        justify-content: space-between;
      }
      .stat-label {
        color: #666;
      }
      .stat-value {
        color: #333;
        font-weight: bold;
      }
      h3 {
        margin: 0 0 15px 0;
        font-size: 16px;
        color: #333;
      }
      .logs-panel {
        grid-column: 1 / -1;
      }
      #logs {
        max-height: 200px;
      }
      .logs-panel .stat-line {
        display: block;
        padding: 3px 0;
        font-size: 11px;
      }
      input[type="file"] {
        margin-bottom: 10px;
        width: 100%;
      }
      audio {
        width: 100%;
        margin-bottom: 10px;
      }
      .full-width {
        grid-column: 1 / -1;
      }
    </style>
  </head>
  <body>
    <h1>Audio Opus Encode/Decode Test</h1>
    <p style="text-align: center; color: #666">
      Select an audio file → Encode with Opus → Decode → Playback
    </p>

    <div class="container">
      <!-- Input Audio -->
      <div class="panel">
        <div class="panel-title">Source: Audio File</div>
        <audio id="sourceAudio" controls src="/example.mp3"></audio>
        <div class="status" id="sourceStatus">Loading example.mp3...</div>
        <div class="stats">
          <div class="stat-line">
            <span class="stat-label">File:</span>
            <span class="stat-value" id="fileName">example.mp3</span>
          </div>
          <div class="stat-line">
            <span class="stat-label">Duration:</span>
            <span class="stat-value" id="fileDuration">-</span>
          </div>
          <div class="stat-line">
            <span class="stat-label">Sample Rate:</span>
            <span class="stat-value" id="fileSampleRate">-</span>
          </div>
        </div>
      </div>

      <!-- Output Audio -->
      <div class="panel">
        <div class="panel-title">Output: Decoded Opus</div>
        <div class="status" id="outputStatus">Ready</div>
        <div class="controls">
          <button onclick="startEncoding()">Start Encode/Decode</button>
          <button onclick="stopEncoding()" class="danger">Stop</button>
        </div>
        <div class="stats">
          <div class="stat-line">
            <span class="stat-label">Encoded Chunks:</span>
            <span class="stat-value" id="encodedChunks">0</span>
          </div>
          <div class="stat-line">
            <span class="stat-label">Decoded Chunks:</span>
            <span class="stat-value" id="decodedChunks">0</span>
          </div>
          <div class="stat-line">
            <span class="stat-label">Buffer (ms):</span>
            <span class="stat-value" id="bufferMs">0</span>
          </div>
          <div class="stat-line">
            <span class="stat-label">Is Playing:</span>
            <span class="stat-value" id="isPlaying">no</span>
          </div>
        </div>
      </div>

      <!-- Logs -->
      <div class="panel logs-panel">
        <h3>Event Logs</h3>
        <div class="stats" id="logs"></div>
      </div>
    </div>

    <!-- Polyfills for Safari iOS 15 (must load before main module) -->
    <script src="/polyfills/encodedAudioChunk.js"></script>
    <script src="/polyfills/audioData.js"></script>

    <script type="module">
      // Define log function FIRST before anything else
      function log(message, isError = false) {
        console.log("[test-audio] " + message);
        const logsDiv = document.getElementById("logs");
        if (!logsDiv) return;
        const time = new Date().toLocaleTimeString();
        const entry = document.createElement("div");
        entry.className = "stat-line";
        entry.style.color = isError ? "#d32f2f" : "#333";
        entry.textContent = `[${time}] ${message}`;
        logsDiv.insertBefore(entry, logsDiv.firstChild);
        if (logsDiv.children.length > 50)
          logsDiv.removeChild(logsDiv.lastChild);
      }

      function updateStatus(element, message, isError = false, isSuccess = false) {
        const statusDiv = document.getElementById(element);
        if (!statusDiv) return;
        statusDiv.textContent = message;
        statusDiv.className = "status";
        if (isError) statusDiv.classList.add("error");
        if (isSuccess) statusDiv.classList.add("success");
        log(message, isError);
      }

      log("Script starting...");

      import { OpusAudioDecoder } from "/opus_decoder/opusDecoder.js";
      log("OpusAudioDecoder imported");

      let initAudioRecorder = null;
      let moduleLoaded = false;
      
      (async function loadModule() {
        try {
          log("Loading opusDecoder module...");
          const opusModule = await import(
            `/opus_decoder/opusDecoder.js?t=${Date.now()}`
          );
          initAudioRecorder = opusModule.initAudioRecorder;
          moduleLoaded = true;
          log("OpusStreamer module loaded: " + (initAudioRecorder ? "success" : "failed"));
        } catch (err) {
          console.error("Error loading modules:", err);
          log("Error loading modules: " + err.message, true);
        }
      })();

      let state = {
        audioFile: null,
        audioElement: null,
        audioStream: null,
        audioRecorder: null,
        opusDecoder: null,
        encodedChunks: 0,
        decodedChunks: 0,
        isEncoding: false,
      };

      let audioContext = null;
      let audioWorkletNode = null;
      let audioMessageChannel = null;

      // Auto-load example.mp3 when page loads
      const audioElement = document.getElementById("sourceAudio");
      state.audioElement = audioElement;
      
      audioElement.onloadedmetadata = () => {
        document.getElementById("fileDuration").textContent = 
          audioElement.duration.toFixed(2) + "s";
        updateStatus("sourceStatus", "Audio file loaded", false, true);
        state.audioFile = true; // Mark as ready
      };

      audioElement.onerror = () => {
        updateStatus("sourceStatus", "Error loading example.mp3", true);
      };

      let scriptProcessorNode = null; // Fallback for Safari 15
      let audioBufferQueue = []; // Buffer for ScriptProcessorNode

      async function initAudioSystem() {
        try {
          // AudioContext is already created and resumed in startEncoding() click handler
          // to preserve the user gesture context (required for iOS 15).
          // Only create a new one if it doesn't exist yet.
          if (!audioContext || audioContext.state === "closed") {
            audioContext = new (window.AudioContext || window.webkitAudioContext)({
              sampleRate: 48000,
            });
          }

          // Check if AudioWorklet is supported (Safari 15 doesn't support it)
          if (audioContext.audioWorklet) {
            await audioContext.audioWorklet.addModule(
              `audio-worklet1.js?t=${Date.now()}`
            );
            
            audioWorkletNode = new AudioWorkletNode(
              audioContext,
              "jitter-resistant-processor"
            );

            // Tạo MessageChannel để truyền audio data vào AudioWorklet
            audioMessageChannel = new MessageChannel();

            // Gửi port2 vào AudioWorklet để nhận decoded audio data
            audioWorkletNode.port.postMessage(
              { type: "connectWorker", port: audioMessageChannel.port2 },
              [audioMessageChannel.port2]
            );

            // Kết nối với loa để phát âm thanh
            audioWorkletNode.connect(audioContext.destination);

            audioWorkletNode.port.onmessage = (event) => {
              const { type, bufferMs, isPlaying } = event.data;
              if (type === "bufferStatus") {
                document.getElementById("bufferMs").textContent = bufferMs.toFixed(0);
                document.getElementById("isPlaying").textContent = isPlaying ? "yes" : "no";
              }
            };
            
            log("✓ Audio system initialized (AudioWorklet)");
          } else {
            // Fallback: Use ScriptProcessorNode for Safari 15
            log("AudioWorklet not supported, using ScriptProcessorNode fallback");
            
            scriptProcessorNode = audioContext.createScriptProcessor(4096, 2, 2);
            audioBufferQueue = [];
            
            scriptProcessorNode.onaudioprocess = (e) => {
              const outputLeft = e.outputBuffer.getChannelData(0);
              const outputRight = e.outputBuffer.getChannelData(1);
              const bufferLength = outputLeft.length;
              
              // Fill from queue
              for (let i = 0; i < bufferLength; i++) {
                if (audioBufferQueue.length > 0) {
                  const sample = audioBufferQueue.shift();
                  outputLeft[i] = sample.left;
                  outputRight[i] = sample.right;
                } else {
                  outputLeft[i] = 0;
                  outputRight[i] = 0;
                }
              }
              
              // Update UI
              const bufferMs = (audioBufferQueue.length / audioContext.sampleRate) * 1000;
              document.getElementById("bufferMs").textContent = bufferMs.toFixed(0);
              document.getElementById("isPlaying").textContent = audioBufferQueue.length > 0 ? "yes" : "no";
            };
            
            scriptProcessorNode.connect(audioContext.destination);
            log("✓ Audio system initialized (ScriptProcessorNode fallback)");
          }

          return true;
        } catch (e) {
          log("Audio system init error: " + e.message, true);
          console.error("Audio init error:", e);
          if (audioContext && audioContext.state !== "closed") {
            audioContext.close().catch(() => {});
          }
          audioContext = null;
          return false;
        }
      }
      
      // Function to add decoded audio to playback
      function addDecodedAudioToPlayback(channelData, sampleRate, numberOfChannels) {
        if (audioWorkletNode && audioMessageChannel) {
          // Use AudioWorklet path
          audioMessageChannel.port1.postMessage({
            type: "audioData",
            channelData: channelData,
            sampleRate: sampleRate,
            numberOfChannels: numberOfChannels,
          });
        } else if (scriptProcessorNode) {
          // Use ScriptProcessorNode fallback path
          const leftChannel = channelData[0];
          const rightChannel = channelData.length > 1 ? channelData[1] : channelData[0];
          
          for (let i = 0; i < leftChannel.length; i++) {
            audioBufferQueue.push({
              left: leftChannel[i],
              right: rightChannel[i]
            });
          }
          
          // Limit buffer size
          const maxBufferSize = 48000 * 2; // 2 seconds
          if (audioBufferQueue.length > maxBufferSize) {
            audioBufferQueue.splice(0, audioBufferQueue.length - maxBufferSize);
          }
        }
      }

      async function startEncoding() {
        log("startEncoding() called");
        console.log("startEncoding() - state:", state);
        console.log("initAudioRecorder:", initAudioRecorder);
        console.log("moduleLoaded:", moduleLoaded);

        // Check if module is loaded
        if (!initAudioRecorder) {
          log("ERROR: initAudioRecorder not loaded yet!", true);
          updateStatus("outputStatus", "Module not loaded. Please wait and try again.", true);
          return;
        }

        if (!state.audioFile || !state.audioElement) {
          updateStatus("outputStatus", "Please select an audio file first", true);
          return;
        }

        try {
          // IMPORTANT: On iOS 15 Safari, BOTH AudioContext.resume() AND
          // HTMLMediaElement.play() require a user gesture context.
          // The gesture context is lost after the first await, so we must
          // trigger ALL gesture-gated APIs synchronously BEFORE any await.

          // 1) Close old context (fire-and-forget to preserve gesture)
          if (audioContext && audioContext.state !== "closed") {
            audioContext.close().catch(() => {});
          }

          // 2) Create new AudioContext and resume — synchronously in click handler
          audioContext = new (window.AudioContext || window.webkitAudioContext)({
            sampleRate: 48000,
          });
          const resumePromise = audioContext.resume();
          log("AudioContext created and resume() called in click handler");

          // 3) Unlock the audio element for playback — synchronously in click handler.
          //    iOS requires play() in a user gesture; once unlocked, later play() calls work.
          const audioElement = state.audioElement;
          audioElement.currentTime = 0;
          const playPromise = audioElement.play();
          log("audioElement.play() called in click handler to unlock playback");

          // Wait for both resume and play unlock with timeout
          try {
            const timeoutPromise = new Promise((_, reject) =>
              setTimeout(() => reject(new Error("Resume timeout")), 3000)
            );
            await Promise.race([resumePromise, timeoutPromise]);
            log("AudioContext resumed successfully (state: " + audioContext.state + ")");
          } catch (resumeErr) {
            log("AudioContext resume error/timeout: " + resumeErr.message, true);
          }

          // Wait for play unlock, then pause — we just needed to unlock it
          try {
            await playPromise;
            log("audioElement unlocked for playback");
          } catch (playErr) {
            log("audioElement unlock play error: " + playErr.message, true);
          }
          audioElement.pause();
          audioElement.currentTime = 0;

          log("AudioContext state after resume: " + audioContext.state);

          log("Initializing audio system...");
          // Init audio system (pass already-resumed audioContext)
          const initSuccess = await initAudioSystem();
          log("initAudioSystem result: " + initSuccess);

          if (!initSuccess || !audioContext) {
            updateStatus("outputStatus", "Failed to initialize audio system", true);
            return;
          }

          // Safari không hỗ trợ captureStream, dùng Web Audio API thay thế
          log("Creating MediaElementSource...");
          
          // Tạo MediaStream từ audio element qua Web Audio API (Safari compatible)
          const sourceNode = audioContext.createMediaElementSource(audioElement);
          log("Created sourceNode");
          
          const streamDestination = audioContext.createMediaStreamDestination();
          log("Created streamDestination");
          
          // Kết nối: audioElement -> streamDestination (để capture stream)
          // Và: audioElement -> destination (để nghe audio gốc - tùy chọn)
          sourceNode.connect(streamDestination);
          // sourceNode.connect(audioContext.destination); // Bỏ comment nếu muốn nghe audio gốc
          log("Connected nodes");
          
          state.audioStream = streamDestination.stream;
          log("Got audio stream: " + (state.audioStream ? "yes" : "no"));
          document.getElementById("fileSampleRate").textContent = audioContext.sampleRate + " Hz";

          // Init Opus Encoder
          log("Initializing Opus Encoder...");
          const audioRecorderOptions = {
            encoderApplication: 2051,
            encoderComplexity: 0,
            encoderFrameSize: 20,
            timeSlice: 100,
          };

          state.audioRecorder = await initAudioRecorder(
            state.audioStream,
            audioRecorderOptions,
            audioContext
          );
          log("Opus Encoder initialized: " + (state.audioRecorder ? "yes" : "no"));

          let audioTimestamp = 0;
          state.encodedChunks = 0;
          state.decodedChunks = 0;

          state.audioRecorder.ondataavailable = (typedArray) => {
            state.encodedChunks++;
            log("Encoded chunk " + state.encodedChunks);
            document.getElementById("encodedChunks").textContent = state.encodedChunks;

            const chunk = new EncodedAudioChunk({
              timestamp: audioTimestamp,
              type: "key",
              data: typedArray,
            });
            
            if (state.opusDecoder) {
              state.opusDecoder.decode(chunk);
            }
            
            audioTimestamp += 85333; // Increment timestamp for next chunk
          };

          // Init Opus Decoder
          log("Initializing Opus Decoder...");
          state.opusDecoder = new OpusAudioDecoder({
            output: async (audioData) => {
              state.decodedChunks++;
              log("Decoded chunk " + state.decodedChunks);
              document.getElementById("decodedChunks").textContent = state.decodedChunks;

              const channelData = [];
              for (let i = 0; i < audioData.numberOfChannels; i++) {
                const channel = new Float32Array(audioData.numberOfFrames);
                audioData.copyTo(channel, { planeIndex: i });
                channelData.push(channel);
              }

              // Gửi audio data đến playback (hỗ trợ cả AudioWorklet và ScriptProcessorNode)
              addDecodedAudioToPlayback(channelData, audioData.sampleRate, audioData.numberOfChannels);
              audioData.close();
            },
            error: (e) => log("Opus decoder error: " + e.message, true),
          });

          log("Configuring Opus Decoder...");
          state.opusDecoder.configure();

          // Start encoder với timeout (iOS 15 có thể bị treo)
          log("Starting Opus Encoder...");
          try {
            const startPromise = state.audioRecorder.start({
              timeSlice: audioRecorderOptions.timeSlice,
            });
            const startTimeout = new Promise((_, reject) => 
              setTimeout(() => reject(new Error("Recorder start timeout")), 5000)
            );
            await Promise.race([startPromise, startTimeout]);
            log("Opus Encoder started");
          } catch (startErr) {
            log("Opus Encoder start error/timeout: " + startErr.message, true);
            updateStatus("outputStatus", "Failed to start encoder. iOS may require HTTPS.", true);
            return;
          }

          // Play audio source (element was already unlocked in click handler above)
          log("Playing audio source...");
          audioElement.currentTime = 0;
          try {
            await audioElement.play();
            log("Audio playing");
          } catch (playErr) {
            log("Audio play error: " + playErr.message, true);
          }

          state.isEncoding = true;
          updateStatus("outputStatus", "Encoding/Decoding started", false, true);

          // Stop when audio ends
          audioElement.onended = () => {
            stopEncoding();
            log("✓ Audio playback completed");
          };

        } catch (error) {
          updateStatus("outputStatus", "Error: " + error.message, true);
          console.error(error);
        }
      }

      async function stopEncoding() {
        state.isEncoding = false;

        if (state.audioRecorder) {
          try {
            await state.audioRecorder.stop();
          } catch (e) {}
          state.audioRecorder = null;
        }

        if (state.audioElement) {
          state.audioElement.pause();
        }

        if (audioContext && audioContext.state !== "closed") {
          await audioContext.close();
          audioContext = null;
        }

        updateStatus("outputStatus", "Stopped");
      }

      log("Ready - select an audio file to start");
      window.startEncoding = startEncoding;
      window.stopEncoding = stopEncoding;
    </script>
  </body>
</html>
